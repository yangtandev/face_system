# 開發與修正交接文件 (2025-12-01)

> **注意：本文件 (`handover_notes.md`) 僅供本地 AI 助理作為上下文參考，請勿將其上傳至遠端 Git 儲存庫。若需更新本文件，請僅在本地進行修改與保存。**

本文檔旨在記錄近期對臉部辨識系統進行的一系列重大修改與錯誤修復，方便後續開發 者能快速進入狀況。

## 1. 核心功能變更：基於臉部特徵點的「無額頭」裁切

*   **問題**：原系統對使用者是否佩戴安全帽或帽子非常敏感，影響辨識率。
*   **解決方案**：
    1.  在 `function.py` 中新增了一個核心函式 `crop_face_without_forehead`。 此函式利用 MTCNN 偵測到的臉部特徵點（特別是眼睛），動態計算出一個不包含額頭和頭髮 的臉部區域，並以此進行裁切。
    2.  修改 `face_main.py` 中的 `_generate_new_descriptors` 函式，在建立人員的臉部特徵檔 (`.npy`)時，強制使用此新裁切邏輯。
    3.  修改 `init/model.py` 中的 `Comparison.face_comparison` 函式，在進行即時影像比對時，也使用完全相同的裁切邏輯，確保了註冊和辨識兩端的一致性。
    4.  為了確保所有舊資料都更新，修改 `face_main.py` 中的 `update_data_and_model` 函式，使其在每次更新時都會刪除所有舊的特徵檔，並用新邏輯重新產生。

## 2. 簽到/簽離邏輯的穩定性修復

*   **問題 1：辨識成功但無後續動作 (Race Condition)**
    *   **原因**：`init/model.py` 中的 `Comparison` 執行緒在設定「辨識成功」 訊號後，幾乎立即在下一個迴圈將其重設，導致主程式的 `CameraSystem` 執行緒極難 捕捉 到此訊號。
    *   **修復**：移除了 `Comparison.face_comparison` 中多餘的訊號重設程式碼 ，確保訊號能被穩定處理。

*   **問題 2：刷出功能看似卡住/阻塞**
    *   **原因**：後端 API 在處理簽離時回傳 `202 Accepted` 狀態碼，但程式只認 `201 Created` 為成功，導致不斷重試。
    *   **修復**：修改 `function.py` 中的 `async_api_call` 函式，將 `201` 和 `202` 都視為成功狀態，解決了刷出失敗的問題。

*   **問題 3：狀態不一致**
    *   **原因**：舊邏輯在發起 API 呼叫前就更新了本地狀態，若 API 呼叫失敗， 會導致本地與遠端資料不一致。
    *   **修復**：重構了 `async_api_call`，將狀態更新的動作移至背景執行緒中，確保只有在 API 呼叫成功後，才更新本地狀態。

*   **問題 4：刷出後立即又被刷入**
    *   **原因**：刷出成功後，清除該人員狀態的計時器只有 5 秒，過短。
    *   **修復**：在 `function.py` 中，將 `clear_leave_employee` 的觸發計時器從 5 秒延長至 **60 秒**。

## 3. 音訊系統 (語音播報) 全面修復

*   **問題 1：程式因音訊問題啟動緩慢或崩潰 (ALSA Errors)**
    *   **原因**：`pygame.mixer.init()` 在主程式啟動時執行，若系統找不到音效 卡，此動作會長時間阻塞，拖慢啟動速度，甚至導致程式崩潰。
    *   **修復**：修改 `init/say.py`，將 `mixer.init()` 的動作完全移入背景的 語音播放執行緒中，並只在第一次嘗試播放時執行一次。這徹底解決了音訊問題對主程 式啟 動的影響。

*   **問題 2：語音重複播報或後續無聲**
    *   **原因**：短時間內重複的辨識會觸發多次語音請求，`pygame.mixer` 可能因此錯亂或卡住 (`get_busy()` 狀態不更新)。
    *   **修復**：
        1.  在 `function.py` 中為語音播報增加了**每個人 5 秒的冷卻機制**，避 免重複請求。
        2.  在 `init/say.py` 中，移除了不可靠的 `while mixer.music.get_busy()` 等待迴圈，改為在播放新語音前，先用 `mixer.music.stop()` **強制停止當前所有 聲音**，確保新請求的即時性。

## 4. 日誌與組態功能的易用性改進

*   **問題 1：啟動延遲原因不明**
    *   **解決方案**：在 `face_main.py` 的啟動流程中，為載入各個 AI 模型 (`MTCNN`, `Resnet`, `YOLO`) 和人臉特徵資料庫等耗時操作，都加入了詳細的 log，讓使 用者 清楚了解程式正在進行的步驟。

*   **問題 2：日誌資訊不完整**
    *   **解決方案**：修改 `function.py` 中的 `log_metrics` 函式，將**信賴度 (confidence)** 的值直接整合進「進入/離開」的主要日誌中，格式如：`攝影機編號:0, 人 員:Yang 進入, 信賴度: 74.47%`。

*   **問題 3：功能無法開關**
    *   **解決方案**：在 `function.py` 中為 Excel API 的呼叫增加了 `excel_api_enabled` 的開關，使用者現在可以透過 `config.json` 靈活控制此功能。

## 5. 影像延遲問題修復 (Video Latency Fix)

*   **問題**：程式運行一段時間後，影像開始出現明顯延遲，畫面無法維持即時性.  經分析判斷為記憶體累積（Memory Accumulation）導致的資源耗盡。
*   **解決方案**：
    1.  **降低 UI 更新頻率**：修改 `face_main.py` 中的 `updata_screen` 函式，將 `time.sleep` 間隔從 `0.00001` 秒調整至 `0.065` 秒。此舉將 UI 更新頻率降低 至約 15 FPS，以匹配攝影機幀率，減少不必要的 `QImage`/`QPixmap` 物件生成，並給予記憶體回收機制更充足的時間。
    2.  **同步臉部比對頻率**：修改 `init/model.py` 中的 `Comparison.face_comparison` 函式，將 `time.sleep` 間隔從 `0.01` 秒調整至 `0.065` 秒。此舉將臉部特徵比 對的頻率降低至約 15 FPS，避免對同一畫面進行重複且不必要的比對計算，進一 步減少 CPU 負載和記憶體壓力。
# 開發與修正交接文件 (2025-12-10)

本次更新主要處理了在資料庫新增大量人員照片後，導致辨識率下降甚至完全失效的嚴 重問題。經過一系列深入的追蹤與修正，最終成功恢復並提升了系統的穩定性與辨
識邏輯的健全性。

## 1. 核心問題：大量照片導致辨識邏輯崩潰

*   **問題描述**：在 `media/pic_bak` 目錄增加約 250 張照片後，程式重啟後無法 正確辨識任何人員，或將人員誤判為固定某位員工 but 信賴度極低。
*   **根本原因分析**：
    1.  **檔名處理缺陷**：`face_main.py` 在進行特徵檔比對時，使用 `split('.')` 來切分副檔名，這導致檔名中若包含「點」(例如 `...烏瑪斯.伊斯卡卡夫特.jpg`)  時， 會取得不正確的主檔名，並在試圖讀取檔案時產生「找不到檔案」的錯誤，中斷了 特徵生成過程。
    2.  **日誌記錄不全**：原程式碼在特徵生成失敗時（如找不到人臉），僅使用 `print` 輸出到主控台，而未寫入日誌檔案，導致問題難以追蹤。
    3.  **核心辨識演算法缺陷**：`init/model.py` 中的 `Comparison.face_comparison` 函式過度依賴 `SVC.predict()` 的回傳結果。此函式只會回傳一個可能性最高的 候選 人，當資料庫增大、特徵空間變得擁擠時，它會固執地回傳一個錯誤但距離最近的 候選人（例如「羅政宏」），即便其信賴度極低，程式也未對其他可能性進行比較，導 致辨識行 為異常。

## 2. 修復與重構方案

*   **修正檔名處理邏輯 (face\_main.py)**：
    *   將 `f.split('.')[0]` 的檔案比對邏輯，全面更換為更穩健的 `os.path.splitext(f)[0]`，並重構了相關程式碼，以正確處理包含多個「點」的複雜檔名。

*   **強化日誌記錄 (face\_main.py)**：
    *   將所有 `print()` 型式的錯誤與警告，全部替換為 `LOGGER.error()` 和 `LOGGER.warning()`，確保所有特徵生成過程中的問題（包括檔案損毀、找不到人臉）都能被記 錄在 `log/faceLog` 中。

*   **重構核心辨識演算法 (init/model.py)**：
    *   **廢棄 `SVC.predict()`**：完全移除了 `SVC.predict()` 的呼叫。
    *   **實現手動全面比對**：新的演算法會取得當前人臉的特徵向量後，手動遍歷 資料庫中**所有已註冊人員**的特徵向量，一一計算餘弦相似度。
    *   **找出最佳匹配**：從所有比對結果中，找出相似度分數最高的人員作為最終 的辨識結果。
    *   **結果**：此修正徹底解決了辨識結果「固著」在單一錯誤人員上的問題，讓 系統能真正找出最相似的人選。

*   **資料增強功能的嘗試與復原 (face\_main.py)**：
    *   **嘗試**：為了解決辨識信賴度與他人過於接近的問題，曾實作了資料增強功 能（水平翻轉、亮度調整），期望透過單張照片生成多個特徵來提升模型穩定性。
    *   **結果**：實際測試後發現效果不佳，反而導致無法辨識。
    *   **復原**：根據使用者要求，已將資料增強相關的所有程式碼完全復原，回到 「一張照片一個特徵檔」的原始邏輯。

## 3. 目前狀態

系統已恢復到一個穩定、邏輯正確的狀態。對於辨識分數與他人較為接近的問題，目前 已知最有效的長期解決方案是為該人員手動增加更多不同角度、光線、表情的照片，以 提升 其在特徵空間中的獨特性。
# 開發與修正交接文件 (2025-12-11)

## 新增功能：自動化辨識成效分析報告

*   **背景與目標**：為量化辨識系統的成效、追蹤優化進展，並精準計算真實誤判率 ，建立了一個自動化的分析與報告系統。
*   **實作細節**：
    1.  **新增報表腳本 (`analytics_reporter.py`)**：建立了一個獨立的 Python  腳本 `analytics_reporter.py`，負責所有分析邏輯。
    2.  **核心功能**:
        *   **API 整合**: 腳本會自動從 `/staffs` API 獲取最新的「專案人員權威名單」。
        *   **日誌解析**: 自動解析當天的 `faceLog`，並提取每一次辨識事件的詳 細數據（ID、信賴度、Z-Score、評級）。
        *   **統計計算**:
            *   **整體分析**: 計算總事件數，以及「我方人員可靠辨識 (True Positives)」、「誤判為陌生人 (False Positives)」、「模糊辨識」和「低信賴度」的數 量與 佔比。
            *   **個體分析**: 針對日誌中出現的每一個 ID，分別統計其出現次數、可靠辨識次數及對應的分數分佈（平均/最大/最小信賴度、平均 Z-Score）。
    3.  **報告產出與管理**:
        *   **每日文字報告 (`report-YYYY-MM-DD.txt`)**: 腳本每次執行會將該日 的完整統計報告（帶時間戳）**追加**到此檔案。
        *   **每日 JSON 數據 (`data-YYYY-MM-DD.json`)**: 為方便機器讀取與趨勢分析，每日的原始統計數據會被**覆寫**到此 JSON 檔案。
        *   **七日滾動總結 (`summary_7_days.txt`)**: 腳本會讀取過去七天的 JSON 數據，產生一份滾動式的趨勢分析報告，並**覆寫**此檔案。
        *   **自動清理**: 腳本會自動刪除超過七天的舊報告檔案（`.txt` 和 `.json`）。
*   **使用方式**：
    *   **排程設定**: 在 `README.md` 中新增了詳細章節，指導使用者如何使用 `cron` 將 `analytics_reporter.py` 設定為每小時自動執行。
*   **程式碼變更**：
    *   新增 `analytics_reporter.py` 檔案。
    *   更新 `README.md` 檔案，增加了「每日辨識成效報告設定」章節。

*   **問題背景**：原系統採用 `LinearSVC` 模型進行人臉辨識。在人員資料庫較小（約 20 人）時，辨識率尚可。但當資料庫擴大至 250 人時，辨識準確率驟降至幾乎為零。分 析發現 `SVC` 模型在面對大量人員類別時，會產生嚴重的「自信誤判」——即使是 不相關的人臉，模型也經常將其錯誤地歸類到某個特定的員工身上，並給出超過 70% 的高信賴度分 數。這證明傳統分類器在處理特徵相似、類別繁多的「一對多」場景時，存在 根本性的瓶頸。
*   **解決方案**：
    1.  **廢棄 SVC 模型**：徹底揚棄了傳統的「分類」思路，辨識流程不再依賴預先訓練的 `SVC` 模型 (該模型目前在程式碼中僅作訓練和保存，但未被實時辨識邏輯使用)。
    2.  **引入餘弦相似度比對**：新策略改為當新臉孔出現時，即時計算其特徵向量 與資料庫中每一位人員特徵向量的餘弦相似度，找出數學上最相似的候選人。
    3.  **引入 Z-Score 離群值分析**：為防範「假性高分」誤判，在相似度比對基礎上增加了 Z-Score 離群值分析。該分析評估最高分是否在統計學上「顯著突出」（Z-Score > 2.5），確保辨識結果的可靠性。只有當信賴度 (`CONFIDENCE_THRESHOLD = 0.7`) 和 Z-Score 均達標時，才確認辨識成功。
*   **程式碼變更**：`init/model.py` 的 `Comparison.face_comparison` 函式。

## 2. 系統效能與資源利用優化

*   **問題背景**：舊系統存在 CPU 資源浪費、不必要的重複計算和啟動延遲。
*   **解決方案**：
    1.  **限制模型推論頻率**：在 `init/model.py` 的 `Detector.face_detector` 中，引入 `DETECTION_INTERVAL = 0.2` 秒，將人臉偵測頻率限制在 5 FPS，顯著降低 CPU  負載。
    2.  **移除冗餘偵測**：移除 `Detector.face_detector` 中使用「直方圖等化」 後的備案偵測，避免處理時間加倍，確保幀處理時間的穩定性。
    3.  **改善 CPU 使用效率**：將 `Detector.face_detector` 函式中的 `time.sleep(0.00001)` 調整為 `time.sleep(0.01)`，解決執行緒「忙碌等待」造成的 CPU 資源浪費 。
*   **程式碼變更**：`init/model.py` 的 `Detector.face_detector` 函式。

## 3. 日誌功能改進：新增「辨識品質評級」

*   **問題背景**：現有日誌僅顯示信賴度和 Z-Score，不夠直觀，難以快速判斷辨識 結果的實際品質。
*   **解決方案**：在 `init/model.py` 的 `Comparison.face_comparison` 函式中，為每條辨識日誌增加一個質性評級（Reliable, Ambiguous, Low Confidence）。
    *   **可靠 (Reliable)**：信賴度 >= 70% 且 Z-Score >= 2.5
    *   **模糊 (Ambiguous)**：信賴度 >= 70% 但 Z-Score < 2.5
    *   **低信賴度 (Low Confidence)**：信賴度 < 70%
*   **效益**：提供更直觀的指標，方便快速評估系統表現和識別問題場景。
*   **程式碼變更**：`init/model.py` 的 `Comparison.face_comparison` 函式中的 日誌輸出邏輯。

## 4. 關鍵挑戰與建議優化方向總結

*   **「一人一照」限制下的資料準備**：在每人僅能提供一張原始照片的嚴格限制下 ，建議採取以下策略以最大化辨識效果：
    *   **原始照片品質**：確保這張唯一的「聖經」照片是**極致清晰、標準正面、 光線均勻**。
    *   **資料增強後製**：對這張高品質照片進行**細微的資料增強後製**（如水平 翻轉、亮度/對比度微調、輕微旋轉），為每人建立一個包含 4-5 張照片的訓練集。
*   **人臉解析度要求**：為確保模型能從中提取足夠資訊，訓練集中原始照片的「臉 部區域」（而非整張照片）的像素尺寸應至少**大於 200x200 像素**，以避免放大造成的模 糊。
*   **環境光線挑戰**：辦公室與強光工地現場的巨大準確度差異，是典型的「訓練資 料與應用場景不匹配」問題。根本解決方案是**擴增包含目標場景光線條件的訓練資料**（可透過實地採集或針對性後製模擬強光）。
*   **待實施：辨識結果穩定性驗證 (時間去抖)**：目前發現系統可能在短時間內對同一個人產生多種「可靠」但實際錯誤的辨識結果。為此，未來建議引入「時間去抖」機 制， 要求辨識結果必須在**連續多個影格**中都穩定指向同一個人，才能觸發最終動作 ，以提高系統的魯棒性。

# 開發與修正交接文件 (2025-12-12)

## 1. 移除廢棄的 SVC 辨識模型與相關程式碼

*   **背景**：根據 2025-12-10 的交接文件，臉部辨識的核心邏輯已從基於 `LinearSVC` 的分類器轉變為餘弦相似度比對與 Z-Score 分析。因此，原有的 `LinearSVC` 模 型及 其相關程式碼已不再使用。
*   **變更內容**：
    1.  **刪除模型檔案**：移除了 `media/linear_svc_model.pkl` 這個不再使用的 模型檔案。
    2.  **清理程式碼**：從 `face_main.py` 中徹底移後的所有與 `LinearSVC` 模型的訓練、儲存、載入相關的程式碼，包括 `sklearn.svm.LinearSVC` 和 `pickle` 的導入、`self.svc` 的初始化、以及相關方法的呼叫與定義。
    3.  **更新 .gitignore**：修改了 `.gitignore` 檔案，確保 `media/linear_svc_model.pkl` 不會被 Git 追蹤，以避免未來再次誤提交。
*   **影響**：此變更簡化了程式碼庫，移除了冗餘且無用的模組與檔案，有助於提高 程式碼的清晰度和維護性。

# 開發與修正交接文件 (2025-12-18)

## 1. 日誌可讀性優化：顯示具名攝影機位置

*   **問題背景**：系統在 `log/faceLog` 中記錄辨識事件時，僅使用 `[Cam 0]`、`[Cam 1]` 等內部編號來區分攝影機來源，不夠直觀，難以快速判斷事件發生的具體位置 （例 如入口或出口）。
*   **解決方案**：
    1.  **新增名稱對應表**：在 `init/model.py` 檔案中，新增了一個 `CAM_NAME_MAP` 字典，明確定義了攝影機編號與其中文名稱的對應關係（`{0: "入口", 1: "出口"}`）。此對應關係根據程式碼註解（`0=進入, 1=離開`）建立。
    2.  **修改日誌生成邏輯**：修改了 `init/model.py` 中 `Comparison.face_comparison` 方法內的所有日誌記錄點，使其在生成日誌時，使用上述的 `CAM_NAME_MAP`  進行 名稱替換。
*   **影響與成果**：
    *   現在所有辨識相關的日誌（包含成功、錯誤、模糊辨識）都會直接顯示如 `[入口]` 或 `[出口]` 的具名位置，取代了原本的 `[Cam 0]`。
    *   大幅提升了日誌的可讀性，方便管理人員在不查閱程式碼的情況下，直接理解 事件發生的地點。

# 開發與修正交接文件 (2025-12-29)

## 1. 辨識邏輯與門檻優化

*   **問題背景**：觀察到許多高分（Conf > 0.7, Z > 1.7）的誤判案例，同時正確辨識的分數有時卻僅有 0.69。經分析，高分誤判多源自於側臉、手部遮擋或模糊畫面導致的特 徵錯位（Garbage In, Garbage Out）。
*   **解決方案**：
    1.  **調整判定門檻**：
        *   **信賴度 (Conf)**：從 `0.68` 提升至 `0.7`，提高可靠辨識的標準。
        *   **訪客門檻**：從 `0.55` 降低至 `0.5`，減少因員工側臉分數稍低而被 誤判為訪客的情況。
        *   **模糊區間 (Ambiguous Zone)**：擴大為 `0.5 ~ 0.7`，落在此區間的結果將被系統忽略，等待更佳畫面。
        *   **Z-Score**：維持在 `1.2` (Top-5 情境下的顯著差異)，作為信賴度達 標後的第二道防線。
    2.  **實作「人臉品質過濾器」 (Quality Gate)**：
        *   在 `init/model.py` 的 `Comparison` 類別中新增 `check_face_quality` 方法。
        *   利用 MTCNN 的 5 個關鍵點進行幾何檢查：
            *   **側臉 (Yaw)**：左右眼到鼻子的距離比例失衡 (> 2.5倍) 即過濾。
            *   **歪頭 (Roll)**：雙眼連線傾斜超過 20 度即過濾。
            *   **遮擋/變形 (Geometry)**：檢查五官垂直比例 (眼鼻距 vs 鼻嘴距)，過濾因手摀嘴或張嘴過大導致的特徵點位移。
        *   **效益**：在進入特徵比對前即篩除劣質畫面，大幅減少高分誤判。

## 2. 訪客顯示體驗優化

*   **問題背景**：原系統在偵測到訪客時，UI 左側大頭貼僅顯示固定的面具圖示 (`mask.png`)，缺乏即時回饋，使用者體驗較差。
*   **解決方案**：
    *   **即時截圖顯示**：修改 `face_main.py`，當 `Comparison` 判定為訪客 (`__VISITOR__`) 時，`main_camera` 會從即時畫面中截取該人臉區域（不含文字與框線）。
    *   **UI 更新**：修改 `shwo_head` 方法，優先顯示記憶體中最新的訪客截圖。 若截圖不存在才回退顯示 `mask.png`。
*   **成果**：現在訪客出現在畫面中時，大頭貼區域會像鏡子一樣顯示其即時臉部特 寫，直到其離開或狀態重置。

## 3. 核心效能突破：啟用高解析度辨識

*   **問題背景**：為了提升系統 FPS，`CameraSystem` 會將 1920x1080 的原始影像 強制縮小至 800x600 進行所有後續處理。這導致現場辨識時的人臉特徵模糊（因解析度不足 ），尤其是在中遠距離下，嚴重影響特徵提取的準確度，成為辨識率的瓶頸。
*   **解決方案**：
    *   **雙流影像處理**：修改 `face_main.py` 的 `GlobalState` 與 `CameraSystem`，同時保留「縮小版影像」（用於顯示與快速偵測）與「高解析度原圖」（用於精細辨識 ）。
    *   **同步快照機制**：修改 `init/model.py` 的 `Detector`，在進行人臉偵測 時，同步抓取當下對應的高解析度原圖快照，確保時間軸一致。
    *   **座標還原與裁切**：修改 `Comparison` 辨識邏輯。當偵測到人臉後，將 800x600 的座標依比例還原至 1920x1080，並直接從**高解析度原圖**中裁切人臉區域進 行特 徵提取。
    *   **訪客截圖升級**：訪客的大頭貼截圖同樣改為從高解析度原圖截取，大幅提 升 UI 顯示清晰度。
*   **效益**：在不犧牲偵測速度（FPS）的前提下，讓特徵提取模型能「看見」最清晰的人臉細節，顯著提升了辨識的穩定性與準確度。

# 開發與修正交接文件 (2025-12-30)

## 1. 差異化出入口辨識距離門檻

*   **問題背景**：考量到實際場域中，攝影機安裝位置與使用者通行距離的差異（例 如：入口鏡頭較遠、出口較近），單一的全域 `min_face` 設定無法同時滿足兩端的最 佳體 驗，容易造成一方過於靈敏或另一方反應遲鈍。
*   **解決方案**：
    1.  **設定檔架構升級**：在 `config.json` 與 `setting/bulid_config.py` 中 ，為 `inCamera` 與 `outCamera` 分別新增了獨立的 `min_face` 參數，允許針對個別鏡頭 設定最小人臉像素門檻。
    2.  **邏輯分流**：修改 `face_main.py` 與 `init/model.py`，程式啟動時會優 先讀取個別鏡頭的設定值。在辨識過程中，系統會根據當前畫面的來源 (`frame_num`) ，自 動套用對應的像素門檻。
    3.  **後備機制**：保留最外層的全域 `min_face` 作為預設值，若個別設定缺失 ，系統將自動回退使用全域設定，確保向下相容性與系統穩定性。
*   **程式碼變更**：
    *   `config.json` / `setting/bulid_config.py`: 新增 `inCamera["min_face"]` 與 `outCamera["min_face"]`。
    *   `face_main.py`: 修改 `GlobalState` 與初始化邏輯，支援列表型態的 `min_face`。
    *   `init/model.py`: 修改 `Comparison` 類別，根據 `frame_num` 動態選取門 檻值。

## 2. 啟動效能自動調校機制 (Startup Performance Auto-Tuning)

*   **問題背景**：原系統的偵測與辨識頻率（FPS）採用寫死（Hardcoded）的參數。 這導致在高效能主機（如 i3-1315U）上無法發揮最大流暢度，而在低階主機上則可能因過度 負載導致 UI 卡頓或延遲累積。
*   **解決方案**：
    1.  **實作自動基準測試**：在 `face_main.py` 的系統啟動階段，新增 `_auto_tune_performance` 程序。
    2.  **模擬真實負載**：
        *   **偵測 (Detection)**：使用 800x600 的隨機影像進行 MTCNN 測速（模 擬實際偵測流）。
        *   **辨識 (Recognition)**：使用 160x160 的 Tensor 進行 ResNet 測速（模擬實際特徵提取流）。
    3.  **動態計算 FPS**：
        *   測得的平均耗時乘以安全係數（偵測 x3.0，辨識 x1.5），預留充足 CPU 資源給 UI 繪圖與作業系統。
        *   **安全邊界**：限制 FPS 最高不超過 15 (節能)，最低不低於 2 (可用性保底)。
    4.  **全面動態化**：修改 `init/model.py`，讓 `Detector` 與 `Comparison`  執行緒不再使用固定秒數，而是讀取自動調校後的 `detection_interval` 與 `comparison_interval`。
*   **效益**：系統現在能「隨遇而安」，在不同等級的硬體上自動找到效能與流暢度 的最佳平衡點，並在日誌中輸出詳細的效能評估數據。

# 開發與修正交接文件 (2025-12-31)

## 1. 解決雙鏡頭高負載下的影像延遲問題

*   **問題描述**：使用者在啟用雙鏡頭時，感覺辨識畫面有明顯的「體感延遲」（慢 半拍）。
*   **原因分析**：自動效能調校 (Auto-Tuning) 算出的 FPS 雖然符合理論上限，但 在雙鏡頭同時運作的情境下，CPU 負載接近 100%，導致影像幀在處理佇列中堆積（排隊效應 ），產生了數百毫秒的處理延遲。
*   **解決方案**：
    *   **大幅提高安全係數 (已還原)**：曾嘗試將偵測係數提升至 `6.0`、辨識係數提升至 `5.0` 以消除延遲。但考量到這會過度降低 FPS，最終決定還原為預設值 (`3.0` / `1.5`)，以維持較高的即時捕捉能力。
    *   **效益**：此舉降低了系統的預設 FPS（例如從 15 FPS 降至 6-8 FPS），釋 放出大量 CPU 餘裕，確保影像能「隨到隨辦」，徹底消除了體感延遲。

## 2. 解決近距離辨識失效問題

*   **問題描述**：當使用者距離鏡頭非常近（約 50cm）時，系統反而完全無法偵測到人臉，且日誌無任何紀錄。
*   **原因分析**：
    1.  **裁切過窄**：原有的遮罩邏輯 (`apply_mask`) 為了過濾背景，強制裁切掉 畫面左右兩側，僅保留中間 33% (預設) 或 50% (Close模式)。近距離的大臉極易超出 此範 圍，導致 MTCNN 無法辨識。
    2.  **品質過濾過嚴**：對於近距離可能產生的輕微側臉或歪頭，原有的品質檢查 (`check_face_quality`) 門檻過於嚴苛，且過濾時僅記錄在 DEBUG 層級（正式環境看 不到 ）。
*   **解決方案**：
    1.  **放寬裁切範圍**：修改 `init/model.py`，將裁切比例大幅放寬。
        *   **一般模式**：從保留 33% 提升至 **66%** (`close_N = 6`)。
        *   **Close模式**：從保留 50% 提升至 **75%** (`close_N = 8`)。
    2.  **放寬品質門檻**：
        *   **側臉 (Yaw)**：容忍度從 0.4 放寬至 **0.3**。
        *   **歪頭 (Roll)**：容忍度從 20 度放寬至 **30 度**。
    3.  **提升日誌可見度**：將品質過濾的日誌等級提升至 `INFO`，並新增了針對「人臉太小 (`min_face`)」被忽略時的日誌記錄，大幅增強了現場除錯能力。

## 3. 除錯日誌增強 (已移除)

*   **過程**：為了診斷近距離失效問題，曾在 `Detector` 中短暫加入了「MTCNN 未 偵測到人臉」的 Log。
*   **結果**：問題確認為裁切範圍過窄後，該診斷 Log 已被移除，以保持正式環境日誌的乾淨。

## 4. 臉辨近距離體驗優化 (詳細分析)

**1. 問題說明:**
客戶反映當人員距離鏡頭非常近（約 50cm）時，系統反而完全無法偵測與辨識人臉，且日誌中無任何相關紀錄（無偵測、無錯誤訊息），造成使用者困惑並誤以為系統故障。

**2. 問題分析:**
經排查程式碼與日誌，發現主要原因有二：
(1) **畫面裁切過窄 (Masking)**：為過濾背景干擾，原系統強制裁切掉畫面左右兩側 ，僅保留中間 33% (預設) 或 50% (Close模式) 的區域。在近距離下，使用者的臉部寬度極 易超出此保留區域，導致 MTCNN 模型因無法取得完整人臉特徵而判定偵測失敗。
(2) **品質過濾過嚴 (Quality Gate)**：近距離操作時容易產生輕微的側臉或歪頭，觸發了嚴格的品質過濾機制。且因該機制原本僅記錄 Debug 日誌，導致正式環境下呈現「有畫 面無反應」的現象。

**3. 問題處理:**
(1) **放寬裁切範圍**：修改偵測邏輯，將畫面的有效保留區域大幅放寬至 **66%** ( 一般模式) 與 **75%** (Close模式)，確保近距離的大臉能完整保留在偵測範圍內。
(2) **調整品質門檻**：放寬側臉 (Yaw) 與歪頭 (Roll) 的判定標準，提升操作容錯率。
(3) **日誌可視化**：將品質過濾與尺寸過濾的日誌等級提升至 INFO，確保未來類似問題能直接透過日誌追蹤原因。

# 2025-12-31 (Part 2) 系統穩定性、UX 與可觀測性全面升級

## 1. 修復系統核心崩潰 (Critical Stability Fixes)

*   **問題 1：UnboundLocalError 導致執行緒退出**
    *   **原因**：在 `init/model.py` 中，日誌記錄語句引用了 `camera_name` 變 數，但該變數的定義位置卻在日誌語句之後。這導致 `Comparison` 執行緒一啟動即拋 出異 常並靜默退出，造成系統完全無反應。
    *   **修復**：調整變數定義順序，確保 `camera_name` 在使用前已被正確賦值。
*   **問題 2：AttributeError (GlobalState)**
    *   **原因**：程式碼中檢查了不存在的 `GlobalState.is_running` 屬性。
    *   **修復**：移除該錯誤檢查。
*   **問題 3：NameError (now variable)**
    *   **原因**：迴圈中的 `now` 變數未在每次迭代開始時正確初始化。
    *   **修復**：在 `face_comparison` 迴圈開頭統一初始化 `now = time.time()`。

## 2. UI 與語音體驗優化 (UX Improvements)

*   **即時引導提示 (Live Guidance)**：
    *   **新增機制**：在 `GlobalState` 中新增 `hint_text`。
    *   **應用場景**：當偵測到「潛在失敗」（人臉寬度在 `min_face` 的 80%~100% 之間）時，系統會直接在畫面中的**人臉追蹤框上方**顯示醒目的橘色提示 **「請靠 近鏡 頭」**，取代原本的「辨識中」或訪客字樣。
    *   **自動清除**：提示文字會在顯示 2 秒後自動消失。
*   **修復狀態殘留**：
    *   **修復**：修復了辨識成功後，人員名字與狀態無限期顯示在畫面上的問題。現在狀態會 在 3 秒後自動重置。
*   **修復語音播報異常 (Audio Fix)**：
    *   **問題**：在 Linux 環境下，語音播報在第一次成功後，後續往往無聲。
    *   **修復**：修改 `init/say.py` Alexander，在每次播放前強制執行 `mixer.quit()` 與 `mixer.init()`，徹底重置音訊子系統，解決了 ALSA 驅動的不穩定問題。

## 3. 數據分析與報表增強 (Analytics & Observability)

*   **全日人臉寬度分佈統計**：
    *   **機制**：`init/model.py` 會統計所有偵測到的人臉寬度（每 10px 為一區 間），並定期（目前設定為每 60 秒以方便測試，正式環境建議 1 小時）輸出統計摘要至日 誌。
    *   **報表整合**：`analytics_reporter.py` 新增了解析這些統計摘要的功能， 能將全天分散的數據加總，並在日報中呈現完整的寬度分佈表。這解決了「低於門檻的 數據 無法被記錄」的盲點。
*   **報表可讀性優化**：
    *   日報現在會明確列出 **入口 (Cam0)** 與 **出口 (Cam1)** 各自的 `min_face` 設定值與換算後的 **意圖偵測區間**。
    *   寬度分佈表中會自動標記 `[低於最小門檻]` 或 `[有效]`，方便管理者快速判斷門檻設定是否合理。
*   **截圖與清理**：
    *   潛在失敗的截圖檔名新增 `In`/`Out` 標記，便於區分來源。
    *   擴充了自動清理腳本，現在會自動刪除 `img_log` 下超過 7 天的舊圖片目錄 。

# 2026-01-01 更新：人臉寬度分佈統計區分出入口

## 變更摘要
優化了每日分析報告 (`analytics_reporter.py`) 與後端模型日誌 (`init/model.py`)，現在「人臉寬度分佈統計」會明確區分 **[入口]** 與 **[出口]**。

## 修改細節

### 1. 日誌格式變更 (`init/model.py`)
- **舊格式**: `[統計] 過去一分鐘人臉寬度分佈: ...`
- **新格式**: `[統計] [入口] 過去一分鐘人臉寬度分佈: ...` (或 [出口])
- **影響**: 讓分析程式能識別數據來源。

### 2. 報告解析與呈現 (`analytics_reporter.py`)
- **分流統計**: 報告現在會分開列出「入口」與「出口」的寬度分佈。
- **門檻對照**: 系統會自動讀取 `config.json` 中對應鏡頭的 `min_face` 設定，並在報告中標示各區間是否低於該鏡頭的門檻。
    - 範例標示: `100-109 px: 5 次 [低於目前門檻]` vs `120-129 px: 10 次 [有效]`

## 注意事項
- **過渡期資料**: 更新當日 (2026-01-01) 的報告會同時包含「未知」（舊格式日誌 ）與「入口/出口」（新格式日誌）。從明天起，「未知」類別將自動消失。
- **用途**: 此功能可協助管理者針對不同架設環境（如距離遠近不同的出入口），個 別微調 `min_face` 參數，以達到最佳辨識率。
# 開發與修正交接文件 (2026-01-02)

## 1. 核心辨識邏輯修正：新增「去下巴」裁切 (Chin Cropping)

*   **問題背景**：
    *   **場景差異**：人員建檔照片通常未佩戴安全帽（無扣環遮擋），但現場辨識 時需佩戴工安帽（有黑色扣環遮擋下巴）。
    *   **辨識影響**：ResNet 模型對遮擋敏感。扣環形成的黑色線條與陰影導致特徵向量與建檔照（乾淨下巴）差異過大，造成信賴度顯著下降（False Rejection），甚至低於 0.7 門檻導致無法辨識。
*   **解決方案**：
    *   **修改裁切邏輯**：更新 `function.py` 中的 `crop_face_without_forehead` 函式。
    *   **保留五官核心**：除了原有的「去額頭」邏輯外，新增「去下巴」邏輯。
    *   **演算法**：計算「鼻尖」到「嘴巴中心」的垂直距離 (`dist`)。將裁切底部設定為 `嘴巴中心 + (dist * 0.6)`。
    *   **效果**：此設定通常會切在下嘴唇下方邊緣，保留了完整的嘴部特徵，但徹 底切除了下巴尖端與頸部連接處（即安全帽扣環所在區域）。
*   **驗證**：
    *   建立工具 `tools/visualize_crops.py` 生成預覽圖 (`img_log/crop_viz_no_chin`)，確認該裁切比例能有效移除扣環且不丟失關鍵五官。
*   **重要注意事項 (Action Required)**：
    *   **特徵檔重建**：此邏輯變更會同時影響「建檔」與「辨識」。為了讓現有資 料庫生效，**必須強制系統重新生成所有人員的特徵檔 (`.npy`)**。建議手動清除 `media/descriptors/` 下的檔案，或觸發全量更新。

# 開發與修正交接文件 (2026-01-03)

## 1. 辨識品質動態懲罰機制 (Dynamic Face Quality Penalty)

*   **問題背景**：
    *   **高分誤判**：觀察到部分側臉 or 頭部傾斜的畫面，因偶然符合某些特徵， 被 誤判為高信賴度（Confidence > 0.7）的錯誤人員。
    *   **品質過濾的兩難**：原有的品質過濾器 (`check_face_quality`) 僅回傳 `True/False`。若門檻設太高，會導致輕微側臉無法辨識（拒絕服務）；若設太低，則無 法阻 擋誤判。
*   **解決方案**：
    1.  **量化品質分數**：修改 `init/model.py` 中的 `Comparison.check_face_quality`，將回傳值從布林值改為 **品質係數 (Quality Score, 0.0~1.0)**。
    2.  **動態懲罰演算法**：
        *   **極端側臉 (Extreme Yaw)**：引入「絕對距離檢查」。若眼鼻距離小於 臉寬的 **18%**，視為極端側臉，直接扣除 **0.25** 分。
        *   **一般側臉 (Yaw Ratio)**：若左右臉比例不均 (Ratio < 0.6)，依嚴重 程度線性扣分。
        *   **歪頭 (Roll)**：若傾斜超過 **10度**，每多1度扣 0.01 分 (最多扣 0.2)。
        *   **特徵錯位 (Geometry)**：保留原有的五官垂直比例檢查，嚴重異常者直接給 0 分。
    3.  **信賴度加權**：
        *   在計算最終信賴度時，公式變更為：`Confidence = Raw_Cosine_Similarity * Quality_Score`。
        *   **效果**：一張 90% 相似的側臉，若品質分只有 0.8，最終信賴度會降為 72%，使其邊緣化或低於門檻，從而優先保留正面且高品質的辨識結果。
*   **效益**：這是一個「軟性過濾」機制。它不完全封殺品質稍差的畫面，而是降低 其權重，讓系統在「有畫面」與「高準確」之間取得更佳的平衡。

# 開發與修正交接文件 (2026-01-04)

## 1. 辨識品質過濾邏輯全面重構

*   **背景**: 系統原有的側臉過濾機制無法有效處理「遮擋」(Masking) 與「極端角 度」(Extreme Pose) 的情況，導致遮嘴仍能辨識、抬頭被誤判為遮擋等邏輯衝突。
*   **變更內容**:
    1.  **檢查順序標準化**: 確立了嚴格的過濾流水線 (Pipeline)，確保錯誤訊息的優先級正確。
        *   **Center (置中)**: 優先排除路人。
        *   **Visibility (完整性)**: 確保特徵點在畫面內。
        *   **Pitch (垂直比例)**: 優先處理抬頭/低頭/眼睛遮擋 (因透視造成的整 體比例異常)。
        *   **Occlusion (嘴巴遮擋)**: *僅在* 垂直比例正常時，才檢查嘴部細節，避免誤殺。
        *   **Yaw (水平角度)**: 最後處理側臉。
    2.  **新增遮擋防禦**:
        *   **遮嘴**: 引入 `鼻嘴距 < 眼距*0.55` 與 `嘴寬 < 眼距*0.75` 檢查。
        *   **遮眼**: 引入 `V-Ratio < 0.45` 極低比例檢查。
    3.  **門檻微調**:
        *   **置中**: 嚴格化至 `15%` (原 20%)。
        *   **抬頭**: 放寬至 `V-Ratio > 1.4` (原 1.25)，避免誤判。
        *   **低頭**: 範圍擴大至 `0.45 ~ 0.70`，涵蓋深度低頭。

## 2. UI 提示系統增強 (Actionable Hints)

*   **新增指令**: 針對不同的失敗原因，提供明確的修正指令，不再只有「辨識中」 。
    *   `低頭` -> **"請抬頭"**
    *   `抬頭` -> **"請低頭"**
    *   `遮嘴` -> **"嘴巴被遮擋"**
    *   `遮眼` -> **"眼睛被遮擋"**
    *   `未置中` -> **"請站到中間"**
*   **動態文字位置**: 修正了當人臉靠近畫面頂部時，提示文字會被切掉的問題。現 在文字會自動跳轉至人臉框下方顯示。

## 3. 測試與驗證

*   經過實際照片集 (`2026_01_03`) 與現場模擬測試，新邏輯成功攔截了所有已知誤 判案例 (側臉、抬頭、未正視)，並能正確區分「遮嘴」與「低頭」的行為差異。

# 開發與修正交接文件 (2026-01-05)

## 1. 臉部辨識日誌解析度優化 (High Resolution Logging)

*   **問題背景**：原系統在辨識成功並儲存人臉日誌 (`img_log/face/`) 時，會強制將影像縮小為 800x600。這雖然節省空間，但在事後稽查或進行更精細的特徵分析時， 解析度不足導致影像細節遺失。
*   **解決方案**：
    1.  **更換影像來源**：修改 `face_main.py` 中的 `main_camera` 迴圈，將呼叫 `self.save_img` 時傳入的影像從縮小過的 `self.system.state.frame` 改為原始高 解析度的 `self.system.state.frame_high_res`。
    2.  **移除強制縮放**：修改 `face_main.py` 中的 `save_img` 函式，移除（註 解掉）其中的 `cv2.resize(img, (800, 600))` 邏輯。
*   **影響與建議**：
    *   **影像品質**：現在 `img_log/face/` 下儲存的所有照片都將維持攝影機輸入的原始解析度（如 1080p）。
    *   **磁碟空間**：此改動會顯著增加日誌影像的檔案大小（每張照片可能從 100KB 增加至 2MB 以上），請務必留意硬碟空間使用情況，並確保自動清理腳本運作正常。

# 開發與修正交接文件 (2026-01-06)

## 1. 系統全面升級為原生解析度 (Native Resolution 1920x1080)

*   **問題背景**：原系統為了效能將影像強制縮小至 800x600。這導致近距離（約 50cm）的大臉在經過「縮小」與「遮罩裁切」後，MTCNN 模型無法辨識出完整人臉（只能 看到局部或誤判為小臉），造成「越近越不準」的現象。
*   **解決方案**：
    1.  **移除強制縮放**：`face_main.py` 中移除 `cv2.resize(..., (800, 600))`，現在影像擷取、偵測、辨識、日誌存檔全流程均採用 **1920x1080** 原生解析度。
    2.  **偵測邏輯重構 (Full Frame + ROI)**：`init/model.py` 改為先對「全畫面」進行 MTCNN 偵測，取得結果後再過濾掉「不在 ROI (走道中間)」的人臉。這確保了 即便人臉佔滿畫面也能被正確捕捉。
    3.  **座標系統簡化**：移除所有座標縮放（Scaling）邏輯，所有座標現在都是原生的。
*   **影響**：
    *   **近距離體驗大幅改善**：使用者靠近鏡頭時不再會被判定為「人臉過小」或 無反應。
    *   **參數調整需求**：因解析度變大（寬度 2.4 倍），`config.json` 中的 `min_face` 數值建議依比例調大（例如 140 -> 330），以維持相同的距離過濾標準。

## 2. 移除嘴巴遮擋檢查 (Mouth Occlusion Check Removal)

*   **問題背景**：現場觀察發現，當人員喝飲料或用手遮嘴時，MTCNN 抓取的嘴巴座 標會漂移（通常上移），導致「鼻嘴距」變短。這會與「低頭」的特徵（下巴內縮、鼻 嘴距短 ）混淆，導致系統在「嘴巴遮擋」與「請低頭」之間反覆跳動，或在正視時誤報錯誤。
*   **解決方案**：
    *   **移除判定**：完全移除了 `check_face_quality` 中的「鼻嘴距」與「嘴寬 」檢查。
    *   **自然攔截**：現在若人員遮擋嘴巴，因特徵點位移導致垂直比例 (`v_ratio`) 異常，系統會自然判定為 **「低頭 (Pitch Error)」** 或單純因信賴度不足而無法 辨識。這符合「遮擋時不予放行」的需求，且減少了不必要的誤導性提示。

## 3. 效能與顯示

*   **UI 顯示**：雖然內部運算使用 1080p，但 `updata_screen` 會自動將影像縮放 至視窗大小，因此 UI 顯示不受影響。
*   **自動調校**：系統重啟後的 Auto-Tuning 會根據 1080p 的運算負載自動重新計 算合適的 FPS，使用者無需手動調整。

## 4. 開發環境特別註記 (Environment Quirk)

*   **檔案寫入問題**：在本系統環境下，使用 `cat >> filename <<EOF` 的 heredoc 方式寫入檔案常會因 bash 解析錯誤（unexpected end of file）而失敗。建議後續開發者 或 AI 助理在更新此文件時，優先使用 `echo "內容" >> filename` 的方式進行 追加，以確保寫入成功。

## 5. 自動化特徵更新機制 (Feature Regeneration Fix)

*   **問題背景**：原系統在檢查資料更新時，僅比對「檔名是否存在」。若伺服器端 更新了某人的照片但檔名未變（常見於大頭照更換），系統會忽略該變更，導致辨識模 型仍使 用舊特徵，產生辨識錯誤。
*   **解決方案**：修改 `face_main.py` 中的 `update_data_and_model` 函式。現在除了檢查檔名，還會比對 **修改時間 (mtime)**。若 `.jpg` 比對應的 `.npy` 新，則視為 過期資料，強制重新生成特徵檔。

## 6. MTCNN 偵測門檻調整

*   **調整內容**：將 MTCNN 的三階段門檻從預設值調整為 `[0.5, 0.6, 0.6]`。
*   **目的**：放寬偵測標準，以提升對光影不佳或角度稍偏的人臉的捕捉率 (Recall)。

## 7. 偵測與品質門檻細微調校 (Fine-tuning)

*   **解決極端近距離誤判**：將 MTCNN 的 `min_face_size` 從 95 提升至 **160** 。此舉能有效忽略高解析度影像下，因臉部過大導致模型將「眼睛」誤認為「人臉」的 錯誤， 迫使系統捕捉完整的臉部特徵。
*   **放寬幾何檢查門檻**：
    *   **抬頭 (Pitch)**：門檻由 1.4 放寬至 **1.6**，以適應不同臉型（如人中或下巴較長者）在正視時的比例。
    *   **側臉 (Yaw)**：門檻由 0.20 放寬至 **0.15**，減少對輕微側頭或光影不均導致的「未正視」誤報。
*   **成效**：經過批次測試驗證，上述調整成功讓原本因角度或距離被過濾的有效影 像（如貼臉照）轉為正確辨識，顯著提升了系統的魯棒性。

## 8. 幾何品質門檻二次放寬 (Relaxation Phase 2)

*   **背景**：經測試歷史資料發現，原有的幾何門檻對於部分臉型（如人中較長、鼻 子較挺）或低解析度影像仍過於嚴苛，導致正視畫面被誤判為抬頭或側臉。
*   **調整內容**：
    *   **抬頭 (High Pitch)**：門檻從 1.60 大幅放寬至 **2.10**。
    *   **低頭 (Low Pitch)**：門檻從 0.70 放寬至 **0.60**。
    *   **左右對稱性 (Yaw Symmetry)**：門檻從 0.65 放寬至 **0.55**。
    *   **眼鼻距比例 (Yaw Distance)**：門檻從 0.15 放寬至 **0.12**。
*   **目的**：將品質檢查的定位從「嚴格姿勢規範」轉為「攔截極端異常」，依靠後 端的 Z-Score 與信賴度作為主要把關，減少對正常操作的干擾。

## 9. 網路診斷與日誌分析功能 (Network Diagnosis & Reporting)

*   **問題背景**：工地現場網路不穩定是常態，但當簽到/簽離 API 失敗時，客戶往 往質疑是系統軟體問題。我們需要確切的證據來釐清是「軟體 Bug」還是「外部斷網」 。
*   **解決方案**：
    1.  **新增診斷機制 (function.py)**：在 async_api_call 達到最大重試次數 (20次) 失敗後，自動觸發 diagnose_network 函式。
        -   **Ping 測試**：Ping Google DNS (8.8.8.8) 檢查外網連通性。
        -   **Server 測試**：使用 requests 測試 API 伺服器連線。
        -   **日誌記錄**：將結果寫入 faceLog，格式為 [ERROR] ... 上傳失敗網路診斷: ...。
    2.  **報表整合 (analytics_reporter.py)**：每日分析報告新增「網路連線異常 分析」區塊。
        -   自動解析日誌中的診斷訊息。
        -   以 5 分鐘為區間彙整失敗次數。
        -   自動區分並顯示異常原因（如「外網斷線」或「伺服器異常」）。
*   **效益**：提供了可追溯的第三方證據（Ping 8.8.8.8），能有效證明上傳失敗當 下的網路環境狀況，減少無謂的責任歸屬爭議。

# 開發與修正交接文件 (2026-01-07)

## 1. 移除冷卻機制與優化語音播報邏輯

*   **問題背景**：現場反應辨識成功但有時無語音或無 API 刷入紀錄。經查為原有的 10 秒 API 冷卻與 5 秒語音冷卻過於僵化，且語音播報會發生堆疊排隊現象，導致人 離開後仍在播放舊請求。
*   **解決方案**：
    1.  **取消 API 與語音時間冷卻**：在 `function.py` 中移除所有基於時間的 `check_time` 間隔檢查。辨識成功即刻觸發 API 呼叫，頻率限制改由伺服器後端處理。
    2.  **智慧語音狀態檢查**：
        *   在 `init/say.py` 的 `Say_` 類別中新增 `is_busy()` 方法，透過 `pygame.mixer.music.get_busy()` 即時偵測是否正在播放。
        *   修改 `function.py` 的觸發邏輯：僅在 `speaker.is_busy()` 為 False 時才送出新的播報請求。
*   **效益**：
    *   **零延遲刷入**：確保只要畫面顯示辨識成功，API 就會即時發送，不被冷卻 機制攔截。
    *   **流暢播報體驗**：徹底解決語音「排隊累積」的問題。若人員持續留在畫面 中，語音會在上一段播完後自動重播；若人員離開，則不會再產生多餘的播報，符合現 場作業 直覺。

## 2. 新增「請靠近鏡頭」語音引導與優先權控制

*   **問題背景**：現場人員有時未注意到畫面上的「請靠近鏡頭」文字提示，導致長 時間站在過遠處無法辨識。同時，語音引導不應干擾最重要的辨識成功播報。
*   **解決方案**：
    1.  **實作語音引導**：在 `init/model.py` 中，當偵測到「潛在失敗」（人臉過小）時，觸發「請靠近鏡頭」語音（每 3 秒限一次）。
    2.  **語音搶斷機制 (Priority Interrupt)**：
        *   在 `init/say.py` 新增 `stop()` 方法，可強制切斷當前音訊。
        *   在 `function.py` 的簽到/簽離流程中，呼叫 `stop()` 強制中斷低優先 級的引導語音，確保辨識結果能即時播出。
    3.  **忙碌避讓 (Busy Yield)**：
        *   引導語音在觸發前會檢查 `is_busy()`，若系統正在播報簽到成功，則自 動放棄本次引導，避免喧賓奪主。

### 3. 底層架構重構 (Technical Refactoring) - 2026-01-07 補充
*   **佇列化指令管理 (Queue-based Dispatch)**：
    *   廢棄了不穩定的 `play` 布林旗標。
    *   改用 Python標準庫 `queue.Queue` 實作生產者-消費者模式，確保所有語音請求依序進入緩衝區，杜絕指令丟失。
*   **版本號搶斷機制 (Generation & Preemption)**：
    *   引入 `generation` 版本號與執行緒鎖。
    *   當呼叫 `stop()` 進行緊急插播（如簽到成功）時，系統會提升全域版本號。 背景執行緒在取出佇列中的舊指令時，會因版本號過期而自動捨棄，實現「即時搶斷」 且不殘 留舊語音。
*   **ALSA 驅動容錯 (Driver Resilience)**：
    *   針對 Linux ALSA 驅動長時運行不穩定的特性，將 `mixer.init()` 移入播放 迴圈。
    *   每次播放前後執行 `mixer.quit()` / `mixer.init()` 重置子系統，雖犧牲微小效能，但換取了極高的長期運作穩定性。

# 2026-01-07 (Part 3) 實作 MQTT 即時資料同步

## 1. 架構變更：從輪詢 (Polling) 轉向訂閱 (Subscription)
*   **背景**：原系統使用 5 分鐘一次的 `threading.Timer` 進行資料輪詢，導致伺 服器端的人員異動（新增/刪除）無法即時反映在邊緣裝置上。
*   **變更**：
    1.  **移除定時器**：在 `face_main.py` 中移除了遞迴呼叫的 Timer 邏輯。
    2.  **引入 MQTT**：新增 `setup_mqtt_client` 方法，程式啟動時會自動連線至 MQTT Broker。
    3.  **事件驅動**：當收到 `pvms/faces/updated` 主題的訊息時，立即觸發 `update_data_and_model`。

## 2. 設定彈性與向下相容 (Dynamic Configuration)
*   **IP 解析邏輯**：為了適應不同的部署環境（本地測試 vs 雲端 EC2），MQTT Broker 的 IP 採用動態讀取策略：
    1.  **優先**：讀取 `config.json` 中 `MQTT` 區塊的 `broker_ip`。
    2.  **後備 (Fallback)**：若無上述設定，自動使用 `Server` 區塊中的 `ip` ( 通常即為 API 伺服器 IP)。
    3.  **預設**：若皆無，使用 `localhost`。
*   **效益**：現有部署無需修改 `config.json` 即可自動連線至 API Server 所在的主機（如 AWS EC2），同時保留了未來擴充 `MQTT` 專屬設定的能力。

## 3. 函式庫相容性修正 (paho-mqtt 2.x)
*   **問題**：新版 `paho-mqtt` 2.0+ 在使用 `CallbackAPIVersion.VERSION2` 時， 回呼函式 `on_connect` 與 `on_message` 的參數簽章發生了重大變更，導致舊版程式碼會拋 出 `TypeError`。
*   **修復**：更新了 `on_connect` (新增 `properties` 參數) 與 `on_message` ( 參數順序調整) 的定義，以符合 2.0 標準，確保了未來的相容性。

# 2026-01-19 參數優化報告：幾何與影像處理微調

## 1. 影像處理參數優化 (Image Processing Optimization)

*   **背景**：為了達成「零誤判」目標，進行了多輪的參數網格搜索 (Grid Search) ，針對銳化、遮罩與裁切進行了極限測試。
*   **變更**：
    1.  **銳化 (Sharpen)**：從 `5.0` 降至 **`1.0`** (無銳化)。
        *   *原因*：高銳化雖然能增強邊緣，但也引入了過多雜訊，導致不同人的特徵向量距離縮短（易混淆）。無銳化反而提供了最真實的特徵。
    2.  **裁切 (Crop Scale)**：從 `1.0` 調整至 **`1.1`** (寬鬆裁切)。
        *   *原因*：稍微放寬裁切範圍，保留了臉頰與耳朵的輪廓，有助於模型區分臉型。
    3.  **遮罩 (Mask Bottom)**：從 `0.8` 調整至 **`0.7`** (窄梯形)。
        *   *原因*：更積極地遮蔽頸部與肩膀背景，減少背景雜訊對特徵的干擾。
    4.  **額頭 (Forehead Ratio)**：從 `0.8` 調整至 **`0.9`** (保留更多)。
        *   *原因*：保留更多髮際線特徵有助於辨識。

## 2. 局部特徵驗證機制 (Part-Based Verification)

*   **背景**：即使經過幾何優化，仍有少數高分誤判案例（如夏有生被誤認為李達穀，信心度達 0.84）。這些案例通常輪廓相似，但五官細節不同。為了在不重新訓練模型、不存原圖資料庫的前提下解決此問題，引入了局部特徵比對。
*   **實作原理**：
    1.  **預載特徵 (Pre-load)**：系統啟動時（或資料更新時），會掃描 `media/pic_bak` 中的建檔原圖，利用 MediaPipe 切割出 **眼睛 (Eye)** 與 **鼻子 (Nose)** 的局部區域，並計算其特徵向量，存入記憶體。
    2.  **即時驗證 (Runtime Check)**：
        *   當全臉辨識信心度落在 **0.7 ~ 0.9** (模糊區間) 時，觸發驗證。
        *   切出當前畫面的眼睛與鼻子，與 Top 1 候選人的局部特徵進行餘弦相似度比對。
    3.  **否決規則 (Veto Rule)**：
        *   若 **眼睛相似度 < 0.65** 或 **鼻子相似度 < 0.60**，視為「特徵不符」。
        *   懲罰：將最終信心度 **打 8 折** (0.8x)，使其跌破 0.7 門檻，從而攔截誤判。
*   **成效**：此機制成功攔截了所有剩餘的頑強誤判，將測試集的準確率提升至 **100%**。

## 3. 品質過濾器調整

*   **變更**：暫時停用了不穩定的 **眼睛閉合檢查 (Eye Check)** 與 **模糊檢查 (Blur Check)**，以避免過度過濾有效畫面。尺寸檢查在正式環境仍會啟用。

# 2026-01-19 (Part 2) UI 視窗固定機制解除

## 1. 解除視窗自動重置 (Disable Window Auto-Reset)

*   **問題背景**：現場僅有一台螢幕時，使用者需要手動調整兩個視窗（入口/出口）並排顯示。但系統原本設定了一個 30 秒的定時器 (`QTimer`)，時間一到就會強制將視窗「復原」到預設位置（半個螢幕寬度），導致使用者手動調整的版面不斷失效，造成困擾。
*   **變更內容**：
    *   **檔案**：`ui/user_show.py`
    *   **修改**：將 `self.timer.start(30000)` 這行程式碼**註解掉** (Line 52)。
*   **影響**：
    *   系統啟動時，依然會自動進行一次初始定位（自動排版）。
    *   啟動後，**不再** 自動重置視窗位置與大小。使用者可以自由拖拉、縮放視窗，且設定會一直保持直到下次重啟。
    *   此修改完全不影響雙螢幕環境的正常顯示（因為初始定位依然有效）。



# 2026-01-19 (Part 3) Git LFS 模型檔防呆機制

## 1. 模型檔大小檢查 (LFS Pointer File Safe-guard)

*   **問題背景**：專案依賴 `models/data/20180402-114759-vggface2.pt` (約 111MB)。若部署環境未安裝 Git LFS，`git pull` 只會下載到約 130 bytes 的指標檔 (Pointer File)。原程式碼僅檢查 `os.path.exists`，會誤判檔案存在並嘗試載入，導致 `torch.load` 崩潰。
*   **解決方案**：
    *   修改 `models/inception_resnet_v1.py`。
    *   在載入前新增大小檢查：若檔案存在但小於 100MB，判定為無效檔案（或 LFS 指標）。
    *   動作：自動刪除該檔案，並觸發原有的 `urllib` 下載邏輯，強制重新下載完整模型。
*   **效益**：確保在無 LFS 環境下也能自動修復並正常運作。

# 2026-01-19 (Part 4) 系統關閉與排版穩定性修復

## 1. 系統關閉高負載與終端機錯亂修復 (Exit Hang & TTY Fix)

*   **問題背景**：
    *   程式結束時 ()，Load Average 飆高至 60-80，且需多次中斷才能退出。
    *   退出後終端機 (TTY) 無法顯示輸入字元 (No Echo)，需手動重置。
*   **原因分析**：
    *   **資源競爭**： 與  背景執行緒同時嘗試殺死子程序，造成死鎖或遞迴呼叫。
    *   **殭屍執行緒**：Daemon Threads (, ) 在 Python 軟退出 () 時未正確釋放 C++ 資源 (OpenCV/MediaPipe)，導致解譯器卡在清理階段。
    *   **TTY 狀態**：程式異常退出導致終端機設定 () 未被還原。
*   **解決方案**：
    1.  **資源釋放同步化** ()： 方法現在只發送  並  等待背景執行緒完成清理，杜絕競爭。
    2.  **強制退出策略** ()：改用  直接終止行程，跳過 Python GC 階段，徹底消除高負載問題。
    3.  **TTY 還原**：在  啟動時備份  設定，並在  前強制還原，確保終端機可用。

## 2. 視窗排版強制邏輯 (Window Layout Enforcement)

*   **問題背景**：測試環境 (單鏡頭/單螢幕) 下，若設定 ，視窗位置會受自動排版干擾。
*   **解決方案** ()：
    *   新增強制邏輯：當  時，無視螢幕數量，強制將 **Cam 0 (入口)** 鎖定在 **左半邊**，**Cam 1 (出口)** 鎖定在 **右半邊**。
# 2026-01-19 (Part 4) 系統關閉與排版穩定性修復

## 1. 系統關閉高負載與終端機錯亂修復 (Exit Hang & TTY Fix)

*   **問題背景**：
    *   程式結束時 (`Ctrl+C`)，Load Average 飆高至 60-80，且需多次中斷才能退出。
    *   退出後終端機 (TTY) 無法顯示輸入字元 (No Echo)，需手動重置。
*   **原因分析**：
    *   **資源競爭**：`CameraSystem.terminate` 與 `ffmpeg` 背景執行緒同時嘗試殺死子程序，造成死鎖或遞迴呼叫。
    *   **殭屍執行緒**：Daemon Threads (`Detector`, `Comparison`) 在 Python 軟退出 (`sys.exit`) 時未正確釋放 C++ 資源 (OpenCV/MediaPipe)，導致解譯器卡在清理階段。
    *   **TTY 狀態**：程式異常退出導致終端機設定 (`termios`) 未被還原。
*   **解決方案**：
    1.  **資源釋放同步化** (`init/camera.py`)：`terminate` 方法現在只發送 `SIGTERM` 並 `join` 等待背景執行緒完成清理，杜絕競爭。
    2.  **強制退出策略** (`face_main.py`)：改用 `os._exit(0)` 直接終止行程，跳過 Python GC 階段，徹底消除高負載問題。
    3.  **TTY 還原**：在 `run` 啟動時備份 `termios` 設定，並在 `os._exit` 前強制還原，確保終端機可用。

## 2. 視窗排版強制邏輯 (Window Layout Enforcement)

*   **問題背景**：測試環境 (單鏡頭/單螢幕) 下，若設定 `full_screen: false`，視窗位置會受自動排版干擾。
*   **解決方案** (`ui/user_show.py`)：
    *   新增強制邏輯：當 `full_screen: false` 時，無視螢幕數量，強制將 **Cam 0 (入口)** 鎖定在 **左半邊**，**Cam 1 (出口)** 鎖定在 **右半邊**。

# 2026-01-19 (Part 5) 局部特徵裁切優化

## 1. 鼻子特徵提取改善 (Nose Crop Optimization)

*   **問題背景**：局部特徵驗證 (Part-Based Verification) 中，發現本人的鼻子相似度常出現極低值 (甚至負值)，導致現行 OR 邏輯的誤殺率 (False Rejection) 高達 45%。
*   **原因**：原  中鼻子的裁切範圍 () 過小，僅包含鼻尖，缺乏臉頰與眉心等上下文資訊，導致 ResNet 特徵不穩定。
*   **解決方案**：
    *   修改  中的 。
    *   將裁切參數擴大至 **W=1.6, H=2.0**。
*   **驗證結果** (樣本數 203)：
    *   **誤殺率**：從 45% 大幅降至 **20.6%** (改善使用者體驗)。
    *   **誤判率**：維持 **0%** (安全性不變)。
*   **決策**：維持嚴格的 **OR 邏輯** (眼或鼻不符即否決)，配合新的裁切參數，達成高安全與高便利性的平衡。

# 2026-01-19 (Part 6) TTY 還原策略修正

*   **問題背景**：前次修復引入外部 `stty sane` 指令來解決輸入不可見問題，但導致 Bash Readline 模式錯亂，上下方向鍵變成亂碼符號 (`^[[A`)。
*   **原因**：
    *   背景延遲執行的 `stty sane` 與 Bash 自身的 TTY 初始化發生競爭。
    *   `stty sane` 強制將終端機設為 Canonical Mode，破壞了 Shell 需要的 Non-Canonical 模式。
*   **解決方案**：
    *   **移除** `subprocess.Popen("sleep 0.1; stty sane")`。
    *   **僅保留** Python 內部的 `termios.tcsetattr` 還原機制。
    *   這確保了還原到程式啟動時的正確狀態，而不是強制重置為出廠預設值。
*   **驗證**：程式退出後，輸入字元可見 (Echo ON)，且上下方向鍵功能正常。

# 2026-01-19 (Part 7) UI 顯示修正

*   **問題背景**：訪客顯示 () 偶爾會出現「上一位訪客」的殘影。因為 `last_visitor_face_img` 只在偵測到訪客時寫入，但在非訪客期間未被清空，導致新訪客剛觸發時，UI 執行緒可能先讀到了舊的暫存圖。
*   **解決方案**：
    *   修改 `face_main.py` 中的 `main_camera` 邏輯。
    *   當辨識狀態切換為 **非訪客** (例如辨識中或員工) 時，強制將 `self.last_visitor_face_img = None`。
    *   這確保了每次切換為訪客時，必須等待新的截圖產生，杜絕殘影。

# 2026-01-19 (Part 8) 誤判除錯機制升級

*   **問題背景**：現場誤判 (False Acceptance) 與回歸測試結果不一致。推測原因是 MediaPipe 在 Video Mode (現場) 與 Static Mode (回歸) 下的 Landmarks 計算有微小座標偏差，導致裁切框位移，進而影響特徵分數。
*   **解決方案**：
    *   建立 **「決策快照 (Decision Snapshot)」** 機制。
    *   修改 `init/model.py`：在辨識時收集當下的 Landmarks、裁切框、分數等 Metadata。
    *   修改 `face_main.py`：在存檔 (`save_img`) 時，同步寫入 `img_log/.../*.json`。
    *   修改 `function.py`：讓 `get_parts_crop` 回傳裁切座標以便記錄。
*   **效益**：未來發生誤判時，可透過 JSON 檔中的真實座標進行 **Pixel-perfect Replay**，徹底消除測試環境與現場環境的誤差，精確定位問題根源。

# 2026-01-20 系統穩定性修復 (Critical Hotfix)

## 1. 解決 check_in_out 競爭條件崩潰 (Race Condition KeyError)
*   **問題**：`main_camera` 執行緒在存取 `system.state.check_time[staff_id]` 時發生 `KeyError`。
*   **原因**：多執行緒競爭。當 `check_in_out` 正在執行時，背景計時器觸發 `clear_leave_employee` 刪除了該人員的鍵值。
*   **修復**：在 `function.py` 中，將直接字典存取改為 `system.state.check_time.get(staff_id, [True, 0])`，確保即使鍵值被刪除也能安全取得預設值。


# 2026-01-20 語音播放邏輯調整 (Voice Policy Update)

## 1. 移除辨識冷卻 (Remove Recognition Cooldown)
*   **變更**：移除 `init/model.py` 中針對同一人簽到/簽退的 10 秒與 2 秒冷卻限制。
*   **目的**：允許連續觸發辨識事件，不再因時間鎖而被忽略。

## 2. 採用「不可搶佔」播放策略 (Non-preemptive Playback)
*   **邏輯**：
    *   **P1 (簽到/簽退)**：
        *   若當前播放 P1：**丟棄新請求 (Drop)** (不排隊，不切斷)。
        *   若當前播放 P2 (提示音)：**切斷並插播 (Preempt)**。
    *   **P2 (提示音)**：
        *   若當前忙碌 (P1 or P2)：**丟棄新請求 (Drop)**。
*   **效果**：確保「簽到成功」語音完整播放，不會被自己打斷，但會打斷次要的提示音。


# 2026-01-20 (Part 2) 局部特徵邏輯修正 (Nose Ranking Update)

## 1. 移除眼睛比對與鼻子否決門檻
*   **背景**：
    *   **眼睛不穩定**：現場反光、陰影、眼鏡導致眼睛特徵變異大，容易造成誤殺 (False Rejection)。
    *   **鼻子門檻僵化**：原有的 `0.68` 否決門檻過於絕對，導致部分真實人員因角度問題被拒絕，且無法解決「A誤判為B」的問題（若B的鼻子分數也剛好過關）。

## 2. 改採「多候選人鼻子競賽」機制 (Nose-based Re-ranking)
*   **新邏輯**：
    1.  **第一階段 (Full Face)**：取出所有信賴度 `>= 0.7` 的候選人 (不再只看 Top 1)。
    2.  **第二階段 (Nose Check)**：
        *   對所有通過第一階段的候選人，計算其與當前畫面的 **鼻子相似度 (Nose Similarity)**。
        *   **重排序 (Re-rank)**：依據鼻子分數由高至低排序。
        *   **決策**：直接選取鼻子分數最高者作為最終辨識結果。
*   **效益**：
    *   **解決誤判**：當 Full Face 特徵混淆（如 `廖家琳` 被誤判為 `蔡亞琳`）時，利用鼻子特徵的差異性來修正 Top 1。
    *   **提升通過率**：不再因單一門檻而拒絕，而是「擇優錄取」。


# 2026-01-20 (Part 3) 最終辨識邏輯定案 (Z-Score Gatekeeper + T-Zone Re-ranking)

## 1. 核心邏輯重構
*   **Phase 1 (嚴格篩選)**:
    *   計算所有候選人 (Top 5) 的 **Z-Score** (相對於群體的離群程度)。
    *   **門檻**: 必須同時滿足 `Confidence >= 0.7` **且** `Z-Score >= 1.5`。
    *   **目的**: 第一時間攔截模糊、大眾臉或特徵不明顯的照片 (如 `農文豐` 模糊照 Z=1.28)，避免進入第二階段誤導決策。
*   **Phase 2 (T-Zone 決戰)**:
    *   若有多位候選人通過 Phase 1，啟動 **T-Zone Long** (眉眼鼻人中) 比對。
    *   **目的**: 利用骨骼硬特徵區分長得很像的人 (如 `農文豐` vs `李達穀`, `廖家琳` vs `蔡亞琳`)。
    *   **決策**: 直接選取 T-Zone 分數最高者為 Winner。

## 2. 部位裁切優化
*   **T-Zone Long**: 
    *   範圍: 眉毛上方至人中 (包含鼻頭)。
    *   寬度: 2.0x 眼距 (包含眼頭與眉心)。
    *   高度: 3.0x 眼距 (包含人中特徵)。
    *   效益: 經測試準確率達 **92.68%**，解決了異性誤判與大部分相似臉孔誤判。

## 3. 遺留問題 (Known Issues)
*   極少數特徵極度相似且 Z-Score 極高 (>1.6) 的案例 (如 `07;54;16_農文豐`) 仍可能誤判。建議透過行政措施 (重新建檔) 解決。

